<!DOCTYPE html>
<html lang="en">
    <head>
        <link href="http://gmpg.org/xfn/11" rel="profile">
        <meta charset="utf-8" />

        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta http-equiv="content-type" content="text/html; charset=utf-8">

        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <!-- <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" /> -->
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css" />

        <link rel="stylesheet" href="style.css">

        <title>Argument Mining Workshop 2023</title>
    </head>

    <body>
        <nav id="nav" class="navbar">
            <div class="container">
				<a href="index.html#news">News</a>
                <a href="index.html#about">About</a>
                <!--<a href="index.html#program">Program</a>-->
				<a href="index.html#call">Call for Papers</a>
				<a href="index.html#dates">Important Dates</a>
				<a href="index.html#shared_task">Shared Tasks</a>
                <!--<a href="index.html#panel_session">Panel Session</a>
                <a href="index.html#keynote">Keynote Speech</a>-->
				<a href="index.html#speakers">Invited Speakers</a>
                <a href="index.html#committee">Committee</a>
                <a href="index.html#sponsors">Sponsors</a>
                <a href="mailto:argmining.org@gmail.com" target="_blank">Contact Us</a>
            </div>
        </nav>

        <div class="wrapper">
            <div class="masthead">
                <div class="workshop_title">
                    <h1>The 10th Workshop on Argument Mining</h1>
                    <br />
                    <p>December 7, 2023 - HYBRID format</p>
                    <p>Co-located with <a href="https://2023.emnlp.org/">EMNLP 2023</a> in Singapore</p>
                </div>
                <div class="links">
                    <a role="button" href="https://twitter.com/ArgminingOrg" target="_blank"><img src="img/logos/twitter_icon.jpeg" alt="twitter" class="icon" /></a>
                    <a role="button" href="mailto:argmining.org@gmail.com" target="_blank"><img src="img/logos/email2.png" alt="email" class="icon" /></a>
                </div>
            </div>

            <section class="section" id="news">
                <p style="text-align:center"><a href="index.html#shared_task">Check out the two shared tasks taking place with ArgMining 2023!</a></p>
            </section>

            <section class="section" id="about">
                <p>Argument mining (also known as "argumentation mining") is a gradually maturing research area within computational linguistics.
				At its heart, argument mining involves the automatic identification of argumentative structures in free text, such as the conclusions, premises, and inference schemes of arguments as well as their interrelations and counter-considerations.
				To date, researchers have investigated argument mining on genres such as legal documents, product reviews, news articles, online debates, user-generated web discourse, Wikipedia articles, scholarly data, persuasive essays, tweets, and dialogues.
				Aside from mining argumentative components, the field focuses on studying argument quality assessment, argument persuasiveness, and the synthesis of argumentative texts.</p>

				<p>Argument mining gives rise to various practical applications of great importance.
				In particular, it provides methods that can find and visualize the main pro and con arguments in a text corpus --- or even in an argument search on the web --- towards a topic or query of interest.
				In instructional contexts, written and diagrammed arguments represent educational data that can be mined for conveying and assessing students' command of course material.
				Moreover, debate technologies like IBM Project Debater that drew a lot of attention recently rely heavily on argument mining tasks.</p>

				<p>While solutions to basic tasks such as component segmentation and classification slowly become mature, many tasks remain largely unsolved, particularly in more open genres and topical domains.
				Success in argument mining requires interdisciplinary approaches informed by NLP technology, theories of semantics, pragmatics and discourse, knowledge of discourse in application domains, artificial intelligence, information retrieval, argumentation theory, and computational models of argumentation.</p>
            </section>

            <section class="section" id="call">
                <h2>Call for Papers</h2>
                <p>ArgMining 2023 invites the submission of long and short papers on substantial, original, and unpublished research in all aspects of argument mining. The workshop solicits <b>long</b> and <b>short</b> papers for oral and poster presentations, as well as <b>demos</b> of argument mining systems and tools.</p>
				<br>
                <p>The topics for submissions include but are not limited to:
                <ul>
                    <li>Automatic identification of argument components (e.g., premises and conclusions), the structure in which they form an argument, and relations between arguments and counterarguments (e.g., support and attack) in as well as across documents</li>
					<li>Automatic assessment of arguments and argumentation with respect to various properties, such as stance, clarity, and persuasiveness</li>
					<li>Automatic generation of arguments and their components, including the consideration of discourse goals (e.g., stages of a critical discussion or rhetorical strategies)</li>
					<li>Creation and evaluation of argument annotation schemes, relationships to linguistic and discourse annotations, (semi-) automatic argument annotation methods and tools, and creation of argumentation corpora</li>
					<li>Argument mining in specific genres and domains (e.g., social media, education, law, and scientific writing), each with a unique style (e.g., short informal text, highly structured writing, and long-form documents)</li>
					<li>Argument mining and generation from multi-modal and/or multilingual data</li>
					<li>Integration of commonsense and domain knowledge into argumentation models for mining and generation</li>
					<li>Combination of information retrieval methods with argument mining, e.g., in order to build the next generation of argumentative (web) search engines</li>
					<li>Real-world applications, including argument web search, opinion analysis in customer reviews, argument analysis in meetings, misinformation detection</li>
					<li>Perspectivist approaches to subjective argument mining tasks for which multiple ”ground truths” may exist, including multi-perspective machine learning and the creation of non-aggregated datasets</li>
					<li>Reflection on the ethical aspects and societal impact of argument mining methods</li>
					<li>Reflection on the future of argument mining in light of the fast advancement of large language models (LLMs)</li>
                </ul>
				<h4>Submission Information</h4>
				<p>Accepted papers will be presented either via oral or poster presentations. They will be included in the EMNLP proceedings as workshop papers. ArgMining 2023 follows <a href="https://www.aclweb.org/adminwiki/index.php?title=ACL_Policies_for_Submission,_Review_and_Citation">ACL’s policies for submission, review, and citation</a>. Moreover, authors are expected to adhere to the ethical code set out in the <a href="https://www.aclweb.org/portal/content/acl-code-ethics">ACL Code of Ethics</a>. Submissions that violate any of the policies will be rejected without review. </p>
				<br>
				<p>SUBMISSION TYPES:</p>
				<ul>
					<li><b>Long</b> paper submissions must describe substantial, original, completed, and unpublished work. Wherever appropriate, concrete evaluation and analysis should be included. Long papers must be no longer than <b>eight</b> pages, including title, text, figures and tables. An unlimited number of pages is allowed for references. Two additional pages are allowed for appendices, and an extra page is allowed in the final version to address reviewers’ comments.</li>
					<li><b>Short</b> paper submissions must describe original and unpublished work. Please note that a short paper is not a shortened long paper. Instead, short papers should have a point that can be made in a few pages, such as a small, focused contribution; a negative result; or an interesting application nugget. Short papers must be no longer than <b>four</b> pages, including title, text, figures and tables. An unlimited number of pages is allowed for references. One additional page is allowed for the appendix, and an extra page is allowed in the final version to address reviewers’ comments.</li>
					<li><b>Demo</b> descriptions must be no longer than <b>four</b> pages, including title, text, examples, figures, tables, and references. A separate one-page document should be provided to the workshop organizers for demo descriptions, specifying furniture and equipment needed for the demo.</li>
				</ul>
				<p>MULTIPLE SUBMISSIONS:</p>
				<p>ArgMining 2023 will not consider any paper that is under review in a journal or another conference or workshop at the time of submission, and submitted papers must not be submitted elsewhere during the review period. ArgMining 2023 will also accept submissions of ARR-reviewed papers, provided that the ARR reviews and meta-reviews are available by the ARR commitment deadline (September 15). However, ArgMining 2023 will not accept direct submissions that are actively under review in ARR, or that overlap significantly (&gt;25%) with such submissions.</p>
				<br>
				<p>SUBMISSION FORMAT AND LINK:</p>
				<p>All long, short, and demonstration submissions must follow the two-column EMNLP 2023 format. Authors are expected to use the LaTeX or Microsoft Word style template (<a href="https://2023.emnlp.org/calls/style-and-formatting/">https://2023.emnlp.org/calls/style-and-formatting/</a>. Submissions must conform to the official EMNLP style guidelines, which are contained in these templates. Submit your paper in PDF format via <a href="https://softconf.com/emnlp2023/ArgMining2023/">https://softconf.com/emnlp2023/ArgMining2023/</a>. <b>For the ARR commitment process, we will provide details later in the summer.</b></p>
				<br>
				<p>DOUBLE BLIND REVIEW:</p>
				<p>ArgMining 2023 will follow the ACL policies for preserving the integrity of double-blind review for long and short paper submissions. Papers must not include authors’ names and affiliations. Furthermore, self-references or links (such as github) that reveal the author’s identity, e.g., “We previously showed (Smith, 1991) …” must be avoided. Instead, use citations such as “Smith previously showed (Smith, 1991) …” Papers that do not conform to these requirements will be rejected without review. Papers should not refer, for further detail, to documents that are not available to the reviewers. For example, do not omit or redact important citation information to preserve anonymity. Instead, use third person or named reference to this work, as described above (“Smith showed” rather than “we showed”). If important citations are not available to reviewers (e.g., awaiting publication), these paper/s should be anonymised and included in the appendix. They can then be referenced from the submission without compromising anonymity. Papers may be accompanied by a resource (software and/or data) described in the paper, but these resources should also be anonymized. <b>Unlike long and short papers, demo descriptions will not be anonymous.</b> Demo descriptions should include the authors’ names and affiliations, and self-references are allowed.</p> 			 
				<br>
				<p>ANONYMITY PERIOD (taken from the EMNLP call for papers in verbatim for the most part):</p>
				<p>The following rules and guidelines are meant to protect the integrity of double-blind review and ensure that submissions are reviewed fairly. The rules make reference to the anonymity period, which runs from 1 month before the direct submission deadline (starting August 1, 2023) up to the date when your paper is accepted or rejected (October 7, 2023). For papers committed from ARR, the anonymity period starts August 15, 2023. Papers that are withdrawn during this period will no longer be subject to these rules. You may not make a non-anonymized version of your paper available online to the general community (for example, via a preprint server) during the anonymity period. Versions of the paper include papers having essentially the same scientific content but possibly differing in minor details (including title and structure) and/or in length. If you have posted a non-anonymized version of your paper online before the start of the anonymity period, you may submit an anonymized version to the conference. The submitted version must not refer to the non-anonymized version, and you must inform the programme chairs that a non-anonymized version exists. You may not update the non-anonymized version during the anonymity period, and we ask you not to advertise it on social media or take other actions that would further compromise double-blind reviewing during the anonymity period. You may make an anonymized version of your paper available (for example, on OpenReview), even during the anonymity period. For arXiv submissions, August 1, 2023 11:59pm UTC-12h (anywhere on earth) is the latest time the paper can be uploaded if you plan a direct submission to the workshop (or August 15, 2023 for papers from ARR committed to the workshops on September 15, 2023).</p>
				<br>
				<p>BEST PAPER AWARDS:</p>
				<p>In order to recognize significant advancements in argument mining science and technology, ArgMining 2023 will include best paper awards. All papers at the workshop are eligible for the best paper awards and a selection committee consisting of prominent researchers in the fields of interest will select the recipients of the awards.</p>
			</section>
			
			<section class="section" id="dates">
                <h2>Important Dates</h2>
                <ul>
                    <li> <b>Submission due:</b> September 1, 2023
					<li> <b>Notification of acceptance:</b> October 7, 2023
					<li> <b>Camera-ready papers due:</b> October 18, 2023
					<li> <b>Workshop:</b> December 7, 2023
				</ul>
				All deadlines are 11.59 pm UTC -12h (“anywhere on Earth”).
            </section>

            <section class="section" id="shared_task">
                <h2>Shared Tasks</h2>
				<p>We are pleased to present two shared tasks as part of ArgMining 2023:</p>
					<section class="subsection" id="image_arg">
						<h3><a href="https://imagearg.github.io/">ImageArg-Shared-Task-2023: The First Shared Task in Multimodal Argument Mining</a></h3>
						<p><b>Task Description:</b></p>
						<p>There has been a recent surge of interest in developing methods and corpora to improve and evaluate 
						persuasiveness in natural language applications. However, these efforts have mainly focused on the textual modality, neglecting the 
						influence of other modalities. To address this limitation, we introduced a new multimodal dataset called ImageArg. This dataset includes 
						persuasive tweets along with associated images, aiming to identify the image's stance towards the tweet and determine its image 
						persuasiveness concerning a specific topic. To further this goal, we designed two shared tasks.</p>
						<p>Participants can choose Task A or Task B, or both.</p>
						<p><u>Task A (Multimodal Argument Stance Classification)</u><br>Given a tweet composed of a text and image, predict whether the given 
						tweet Supports or Opposes the given topic.</p>
						<p><u>Task B (Multimodal Image Persuasiveness Classification)</u><br>Given a tweet composed of text and image, predict whether the image makes the tweet text more Persuasive or Not.</p>
						<p><b>Task Organizers:</b></p>
						<p>Zheixong Liu, Mohamed Elaraby, Yang Zhong, Diane Litman (University of Pittsburgh)</p>
					</section>
					<section class="subsection" id="scholarly_data">
						<h3><a href="https://codalab.lisn.upsaclay.fr/competitions/13334">PragTag-2023: The First Shared Task on Pragmatic Tagging of Peer Reviews</a></h3>
						<p><b>Task Description:</b></p>
						<p>Peer reviews are argumentative texts that discuss the strengths and weaknesses of the paper under-review and provide 
						suggestions for improvement. The automatic analysis of intentions in reviewer argumentation has numerous applications, from 
						the analysis of reviewing practices, to aggregating information from multiple reviews and assisting junior reviewers. However, 
						reviewing practices vary across fields and peer reviewing data for training is scarce; this introduces the danger of performance 
						shift of such automatic analysis across disciplines. With this shared task, we invite the community to explore these challenges,
						using recently introduced multi-domain corpora of peer reviews.</p>
						<p><b>Task Organizers:</b></p>
						<p>Ilia Kuznetsov, Nils Dycke (Technical University of Darmstadt, UKP Lab)</p>
					</section>
			</section> 
			
			<section class="section" id="speakers">
                <h2>Invited Speakers</h2>
                To be confirmed               
            </section>

            <section class="section" id="committee">
                <h2>Committee</h2>
                <h3>Organizing Committee</h3>
                <div id="organizing_committee">
                    <div class="member">
                        <img src="img/people/milad_alshomary.jpg" class="photo" />
                        <div class="details">
                            <p class="name"><a href="https://www.ai.uni-hannover.de/de/institut/team/milad-alshomary">Milad Alshomary</a></p>
                            <p class="email"><a href="mailto:
m.alshomary@ai.uni-hannover.de "><img src="img/logos/email.png" class="email_logo" /><a></p>
                            <img src="img/logos/luh_logo.svg" class="logo" />
                        </div>
                    </div>
                    <div class="member">
                        <img src="img/people/chungchi_chen.jpeg" class="photo" />
                        <div class="details">
                            <p class="name"><a href="http://nlg.csie.ntu.edu.tw/~cjchen/">Chung-Chi Chen</a></p>
                            <p class="email"><a href="mailto:c.c.chen@acm.org"><img src="img/logos/email.png" class="email_logo" /><a></p>
                            <img src="img/logos/aist.png" class="logo" />
                        </div>
                    </div>
                    <div class="member">
                        <img src="img/people/smaranda_muresan.jpg" class="photo" />
                        <div class="details">
                            <p class="name"><a href="http://www.cs.columbia.edu/~smara/">Smaranda Muresan</a></p>
                            <p class="email"><a href="mailto:smara@columbia.edu"><img src="img/logos/email.png" class="email_logo" /></a></p>
                            <img src="img/logos/columbia_university.png" class="logo" />
                        </div>                        
                    </div>        
                    <div class="member">
                        <img src="img/people/joonsuk_park.jpeg" class="photo" />
                        <div class="details">
                            <p class="name"><a href="https://facultystaff.richmond.edu/~jpark/">Joonsuk Park</a></p>
                            <p class="email"><a href="mailto:park@joonsuk.org"><img src="img/logos/email.png" class="email_logo" /></a></p>
                            <img src="img/logos/university_of_richmond.jpeg" class="logo" />
                        </div>                        
                    </div>
                    <div class="member">
                        <img src="img/people/julia_romberg.jpg" class="photo" />
                        <div class="details">
                            <p class="name"><a href="https://www.cimt-hhu.de/en/team/romberg/">Julia Romberg</a></p>
                            <p class="email"><a href="mailto:julia.romberg@hhu.de"><img src="img/logos/email.png" class="email_logo" /></a></p>
                            <img src="img/logos/heinrich_heine_university.png" class="logo" />
                        </div>                        
                    </div>   					
                </div>

                <h3>Program Committee</h3>
                <div id="program_committee">
                <ul class="column"> 
                        <li>Rodrigo Agerri, University of the Basque Country </li>
						<li>Yamen Ajjour, Leibniz Universität Hannover </li>
                        <li>Khalid Al Khatib, University of Groningen </li>
						<li>Safi Eldeen Alzi'abi,  Isra University </li>
						<li>Özkan Aslan, Afyon Kocatepe University</li>
                        <li>Roy Bar-Haim, IBM Research AI</li>
                        <li>Miriam Butt, University of Konstanz</li>						
                        <li>Elena Cabrio, CNRS, Inria, I3S</li>
						<li>Claire Cardie, Cornell University</li>
                        <li>Jonathan Clayton,  University of Sheffield  </li>
                        <li>Johannes Daxenberger, summetix </li>
                        <li>Lorik Dumani, Trier University </li>
						<li>Roxanne El Baff, German Aerospace Center (DLR) </li>
						<li>Ivan Habernal, Technische Universität Darmstadt </li>
						<li>Shohreh Haddadan, University of Luxembourg </li>
						<li>Yufang Hou, IBM Research AI </li>
						<li>Xinyu Hua, Bloomberg AI </li>
                        <li>Lea Kawaletz, HHU Düsseldorf  </li>
                        <li>Christopher Klamm, University of Mannheim </li>   
                        <li>Manika Lamba, University of Illinois Urbana-Champaign</li>	
                    </ul>
                    <ul class="column">
						<li>Gabriella Lapesa, University of Stuttgart </li>
                        <li>John Lawrence, University of Dundee</li>  
						<li>Beishui Liao, Zhejiang University</li>  
						<li>Diane Litman, University of Pittsburgh</li>  
                        <li>Simon Parsons, University of Lincoln  </li>
                        <li>Georgios Petasis, NCSR Demokritos, Athens  </li>
                        <li>Olesya Razuvayevskaya, University of Sheffield  </li>
                        <li>Chris Reed, University of Dundee  </li>
						<li>Patrick Saint-Dizier, IRIT, CNRS</li>
						<li>Robin Schaefer, University of Potsdam  </li>
						<li>Jodi Schneider, University of Illinois Urbana-Champaign</li>
                        <li>Manfred Stede, University of Potsdam </li>
                        <li>Benno Stein, Bauhaus-Universität Weimar  </li>
                        <li>Mohammed Taiye, Linnaeus University  </li>
                        <li>Simone Teufel, University of Cambridge  </li>
						<li>Nicolas Turenne, Guangdong University of Foreign Studies </li>
						<li>Serena Villata, Université de Nice </li>
                        <li>Henning Wachsmuth, Leibniz Universität Hannover </li>
                        <li>Vern R.	Walker, Hofstra University </li>
                        <li>Zhongyu Wei, Fudan University </li>
						<li>Timon Ziegenbein, Leibniz Universität Hannover </li>
                    </ul>
                </div>

            </section>

            <section class="section" id="past_workshops">
                <h2>Past Workshops</h2>
                <div class="table">
                    <ul class="column">
                        <li><a href="https://argmining-org.github.io/2022/" target="_blank">2022</a> (<a href="https://www.aclweb.org/anthology/volumes/2022.argmining-1/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://2021.argmining.org" target="_blank">2021</a> (<a href="https://www.aclweb.org/anthology/volumes/2021.argmining-1/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://argmining2020.i3s.unice.fr/" target="_blank">2020</a> (<a href="https://www.aclweb.org/anthology/volumes/2020.argmining-1/" target="_blank">Proceedings</a>)</li>
                    </ul>
                    <ul class="column">
                        <li><a href="https://events.webis.de/argmining-19/" target="_blank">2019</a> (<a href="https://www.aclweb.org/anthology/volumes/W19-45/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://www.research.ibm.com/haifa/Workshops/argmining18/index.shtml" target="_blank">2018</a> (<a href="https://www.aclweb.org/anthology/volumes/W18-52/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://argmining2017.wordpress.com/" target="_blank">2017</a> (<a href="https://www.aclweb.org/anthology/volumes/W17-51/" target="_blank">Proceedings</a>)</li>
                    </ul>
                    <ul class="column">
					    <li><a href="http://argmining2016.arg.tech/" target="_blank">2016</a> (<a href="https://www.aclweb.org/anthology/volumes/W16-28/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://www.cs.cornell.edu/home/cardie/naacl-2nd-arg-mining/" target="_blank">2015</a> (<a href="https://www.aclweb.org/anthology/volumes/W15-05/" target="_blank">Proceedings</a>)</li>
                        <li><a href="https://www.uncg.edu/cmp/ArgMining2014/" target="_blank">2014</a> (<a href="https://www.aclweb.org/anthology/volumes/W14-21/" target="_blank">Proceedings</a>)</li>
                    </ul>
                </div>

            </section>

            <section class="section" id="policy">
                <h2>Policy</h2>
                <p>We abide by the <a href="https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy" target="_blank">ACL anti-harassment policy</a>.</p>
            </section>

            <section class="section" id="sponsors">
                <h2>Sponsors</h2>
				<div class="sponsors">
                    <img src="img/logos/naver.png" alt="NAVER" />
                    <img src="img/logos/ibm.png" alt="IBM" />
                </div>
            </section>

        </div>


        <div id="footer">
            <div class="dummy">
                <a role="button" href="index.html">&#8613;</a>
            </div>
        </div>
    </body>
</html>
